{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7672930,"sourceType":"datasetVersion","datasetId":4475627}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model 1","metadata":{}},{"cell_type":"code","source":"# Import packages\nimport cv2\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import models\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras import optimizers","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:49:27.745753Z","iopub.execute_input":"2024-03-15T19:49:27.746833Z","iopub.status.idle":"2024-03-15T19:49:27.757210Z","shell.execute_reply.started":"2024-03-15T19:49:27.746790Z","shell.execute_reply":"2024-03-15T19:49:27.756031Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"hists = []","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:49:30.477802Z","iopub.execute_input":"2024-03-15T19:49:30.478791Z","iopub.status.idle":"2024-03-15T19:49:30.484779Z","shell.execute_reply.started":"2024-03-15T19:49:30.478753Z","shell.execute_reply":"2024-03-15T19:49:30.483747Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train_dir = \"/kaggle/input/maleria/cell_images\"\n\nBATCH_SIZE = 16\nIMG_SIZE = (224, 224)\n\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    label_mode=\"categorical\",\n    image_size=IMG_SIZE,\n    validation_split=0.2,\n    subset=\"training\",\n    batch_size=BATCH_SIZE,\n    seed=42,\n)\n\nval_data = tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    label_mode=\"categorical\",\n    image_size=IMG_SIZE,\n    validation_split=0.2,\n    subset=\"validation\",\n    batch_size=BATCH_SIZE,\n    seed=42,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:49:32.657681Z","iopub.execute_input":"2024-03-15T19:49:32.658093Z","iopub.status.idle":"2024-03-15T19:49:42.690313Z","shell.execute_reply.started":"2024-03-15T19:49:32.658060Z","shell.execute_reply":"2024-03-15T19:49:42.689311Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Found 27558 files belonging to 2 classes.\nUsing 22047 files for training.\nFound 27558 files belonging to 2 classes.\nUsing 5511 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print the class names to understand the mapping\nprint(train_data.class_names)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:49:46.423778Z","iopub.execute_input":"2024-03-15T19:49:46.424577Z","iopub.status.idle":"2024-03-15T19:49:46.429801Z","shell.execute_reply.started":"2024-03-15T19:49:46.424537Z","shell.execute_reply":"2024-03-15T19:49:46.428607Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"['Parasitized', 'Uninfected']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data Augmentation with Noise\ndata_augmentation = Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n    layers.experimental.preprocessing.RandomZoom(0.2),\n    layers.experimental.preprocessing.RandomContrast(0.2),\n    layers.GaussianNoise(0.1),  # You can adjust the noise level as needed\n], name =\"data_augmentation\")","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:49:48.602697Z","iopub.execute_input":"2024-03-15T19:49:48.603548Z","iopub.status.idle":"2024-03-15T19:49:48.616936Z","shell.execute_reply.started":"2024-03-15T19:49:48.603513Z","shell.execute_reply":"2024-03-15T19:49:48.616005Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2L(include_top=False, weights='imagenet')\nbase_model.trainable = True\n\ninputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\naugmented_inputs = data_augmentation(inputs)\nx = base_model(augmented_inputs, training=True)\nx = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\noutputs = layers.Dense(2, activation=\"softmax\", name=\"output_layer\")(x)\nmodel_1 = tf.keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:49:50.760243Z","iopub.execute_input":"2024-03-15T19:49:50.761177Z","iopub.status.idle":"2024-03-15T19:50:08.193191Z","shell.execute_reply.started":"2024-03-15T19:49:50.761139Z","shell.execute_reply":"2024-03-15T19:50:08.191948Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:50:08.470358Z","iopub.execute_input":"2024-03-15T19:50:08.470715Z","iopub.status.idle":"2024-03-15T19:50:08.603802Z","shell.execute_reply.started":"2024-03-15T19:50:08.470688Z","shell.execute_reply":"2024-03-15T19:50:08.602737Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Model: \"model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n                                                                 \n data_augmentation (Sequent  (None, 224, 224, 3)       0         \n ial)                                                            \n                                                                 \n efficientnetv2-l (Function  (None, None, None, 1280   117746848 \n al)                         )                                   \n                                                                 \n global_average_pooling (Gl  (None, 1280)              0         \n obalAveragePooling2D)                                           \n                                                                 \n output_layer (Dense)        (None, 2)                 2562      \n                                                                 \n=================================================================\nTotal params: 117749410 (449.18 MB)\nTrainable params: 117236834 (447.22 MB)\nNon-trainable params: 512576 (1.96 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_1.compile(loss=\"categorical_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-4),\n              metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:50:11.080819Z","iopub.execute_input":"2024-03-15T19:50:11.081660Z","iopub.status.idle":"2024-03-15T19:50:11.119445Z","shell.execute_reply.started":"2024-03-15T19:50:11.081621Z","shell.execute_reply":"2024-03-15T19:50:11.118664Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n#     \"best_bleed_model.h5\",\n#     save_best_only=True,\n#     save_weights_only=True,\n#     monitor=\"val_loss\",\n#     verbose=1\n# )\n\n# early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n#     monitor=\"val_loss\",\n#     patience=4,\n#     verbose=1,\n#     restore_best_weights=True\n# )\n\n# reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n#     monitor=\"val_loss\",\n#     factor=0.2,\n#     patience=2,\n#     min_lr=1e-6,\n#     verbose=1\n# )\n\n\n# callbacks = [checkpoint_callback, early_stopping_callback, reduce_lr_callback]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T15:10:08.997033Z","iopub.execute_input":"2024-03-15T15:10:08.997337Z","iopub.status.idle":"2024-03-15T15:10:09.063699Z","shell.execute_reply.started":"2024-03-15T15:10:08.997301Z","shell.execute_reply":"2024-03-15T15:10:09.062545Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('efficientnet.h5', monitor='val_loss', save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:50:13.583084Z","iopub.execute_input":"2024-03-15T19:50:13.583935Z","iopub.status.idle":"2024-03-15T19:50:13.588633Z","shell.execute_reply.started":"2024-03-15T19:50:13.583896Z","shell.execute_reply":"2024-03-15T19:50:13.587524Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"efficientnet = model_1.fit(train_data,\n                             epochs=5,\n                             validation_data=val_data,\n                             batch_size=BATCH_SIZE,\n                             callbacks = checkpoint)\n\nhists.append(efficientnet)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:50:16.254870Z","iopub.execute_input":"2024-03-15T19:50:16.255687Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2024-03-15 19:52:14.802447: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_2/efficientnetv2-l/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"}]},{"cell_type":"code","source":"for hist in hists:\n    print(hist)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:44:34.683946Z","iopub.execute_input":"2024-03-15T19:44:34.685192Z","iopub.status.idle":"2024-03-15T19:44:34.690353Z","shell.execute_reply.started":"2024-03-15T19:44:34.685152Z","shell.execute_reply":"2024-03-15T19:44:34.689214Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"<keras.src.callbacks.History object at 0x7f62f9dc0eb0>\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming hists is a list containing history objects\ndata = []\nfor history in hists:\n    for epoch in history.epoch:\n        row_data = {'epoch': epoch}\n        for metric_name, metric_values in history.history.items():\n            row_data[metric_name] = metric_values[epoch]\n        data.append(row_data)\n\n# Convert the data to a pandas DataFrame\ndf = pd.DataFrame(data)\n\n# Save the DataFrame to a CSV file\ndf.to_csv('history_data.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(efficientnet.history['accuracy'])\nplt.plot(efficientnet.history['val_accuracy'])\nplt.title(\" Model_Accuracy\")\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.legend(['traning_Accuracy', 'Validation_Accuracy'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:12:02.750738Z","iopub.execute_input":"2024-03-15T16:12:02.751073Z","iopub.status.idle":"2024-03-15T16:12:03.079783Z","shell.execute_reply.started":"2024-03-15T16:12:02.751045Z","shell.execute_reply":"2024-03-15T16:12:03.078816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(hists))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:12:03.085942Z","iopub.execute_input":"2024-03-15T16:12:03.086254Z","iopub.status.idle":"2024-03-15T16:12:03.091641Z","shell.execute_reply.started":"2024-03-15T16:12:03.086230Z","shell.execute_reply":"2024-03-15T16:12:03.090545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.plot(hists.history['loss'])\n# plt.plot(hists.history['val_loss'])\n# plt.title(\"Model loss\")\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['traning_loss', 'validation_loss'])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:12:03.093033Z","iopub.execute_input":"2024-03-15T16:12:03.093945Z","iopub.status.idle":"2024-03-15T16:12:03.102523Z","shell.execute_reply.started":"2024-03-15T16:12:03.093883Z","shell.execute_reply":"2024-03-15T16:12:03.101593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"# Load MobileNetV3Large model with pretrained weights\nbase_model = tf.keras.applications.MobileNetV3Large(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n\n# Freeze layers\nbase_model.trainable = True\n\n# Define new top layers\nflatten = Flatten()\nfc1 = Dense(2048, activation='relu')\ndrop1 = Dropout(0.6)\nfc2 = Dense(2, activation='sigmoid')\n\n# Combine layers into a sequential model\nmodel_2 = models.Sequential([\n    base_model,\n    flatten,\n    fc1,\n    drop1,\n    fc2\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:12:03.103696Z","iopub.execute_input":"2024-03-15T16:12:03.104084Z","iopub.status.idle":"2024-03-15T16:12:06.622351Z","shell.execute_reply.started":"2024-03-15T16:12:03.104056Z","shell.execute_reply":"2024-03-15T16:12:06.621381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel_2.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9),\n              loss=BinaryCrossentropy(),\n              metrics=['accuracy'])\n\n# Define learning rate scheduler\ndef scheduler(epoch, lr):\n    if epoch % 7 == 0 and epoch != 0:\n        return lr * 0.1\n    else:\n        return lr\n\nlr_scheduler = LearningRateScheduler(scheduler)\ncheckpoint = ModelCheckpoint('MobileNet.h5', monitor='val_loss', save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:12:06.623787Z","iopub.execute_input":"2024-03-15T16:12:06.624224Z","iopub.status.idle":"2024-03-15T16:12:06.647369Z","shell.execute_reply.started":"2024-03-15T16:12:06.624186Z","shell.execute_reply":"2024-03-15T16:12:06.646509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print model summary\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:12:06.648800Z","iopub.execute_input":"2024-03-15T16:12:06.649234Z","iopub.status.idle":"2024-03-15T16:12:07.086683Z","shell.execute_reply.started":"2024-03-15T16:12:06.649197Z","shell.execute_reply":"2024-03-15T16:12:07.085581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the number of epochs\nepochs = 20\n\n# Train the model\nMobileNet = model_2.fit(train_data,  \n                    epochs=epochs,\n                    validation_data=val_data,  \n                    callbacks=[lr_scheduler, checkpoint])\nhists.append(MobileNet)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:12:07.088040Z","iopub.execute_input":"2024-03-15T16:12:07.088369Z","iopub.status.idle":"2024-03-15T16:40:33.109841Z","shell.execute_reply.started":"2024-03-15T16:12:07.088340Z","shell.execute_reply":"2024-03-15T16:40:33.108891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for hist in hists:\n    print(hist)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:40:33.111230Z","iopub.execute_input":"2024-03-15T16:40:33.111560Z","iopub.status.idle":"2024-03-15T16:40:33.116743Z","shell.execute_reply.started":"2024-03-15T16:40:33.111531Z","shell.execute_reply":"2024-03-15T16:40:33.115738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(MobileNet.history['loss'])\nplt.plot(MobileNet.history['val_loss'])\nplt.title(\"Model loss\")\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['traning_loss', 'validation_loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:40:33.118067Z","iopub.execute_input":"2024-03-15T16:40:33.118444Z","iopub.status.idle":"2024-03-15T16:40:33.416513Z","shell.execute_reply.started":"2024-03-15T16:40:33.118407Z","shell.execute_reply":"2024-03-15T16:40:33.415498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3","metadata":{}},{"cell_type":"code","source":"# Load the base model without the top layers\nbase_model = InceptionResNetV2(include_top=False, weights='imagenet')\n\n# Freeze the base model\nbase_model.trainable = True\n\n# Input layer\ninputs = tf.keras.Input(shape=(224, 224, 3), name=\"input_layer\")\n\n# Augment input images\naugmented_inputs = data_augmentation(inputs)\n\n# Pass augmented inputs through the base model\nx = base_model(augmented_inputs, training=True)\n\n# Global average pooling layer\nx = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\n\n# Output layer\noutputs = layers.Dense(2, activation=\"softmax\", name=\"output_layer\")(x)\n\n# Define the model\nmodel_3= tf.keras.Model(inputs, outputs)\n\n# Display model summary\nmodel_3.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:08:40.775081Z","iopub.execute_input":"2024-03-15T19:08:40.775391Z","iopub.status.idle":"2024-03-15T19:08:52.495589Z","shell.execute_reply.started":"2024-03-15T19:08:40.775364Z","shell.execute_reply":"2024-03-15T19:08:52.494513Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n219055592/219055592 [==============================] - 1s 0us/step\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n                                                                 \n data_augmentation (Sequent  (None, 224, 224, 3)       0         \n ial)                                                            \n                                                                 \n inception_resnet_v2 (Funct  (None, None, None, 1536   54336736  \n ional)                      )                                   \n                                                                 \n global_average_pooling (Gl  (None, 1536)              0         \n obalAveragePooling2D)                                           \n                                                                 \n output_layer (Dense)        (None, 2)                 3074      \n                                                                 \n=================================================================\nTotal params: 54339810 (207.29 MB)\nTrainable params: 54279266 (207.06 MB)\nNon-trainable params: 60544 (236.50 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('InceptionResNet.h5', monitor='val_loss', save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:08:52.497138Z","iopub.execute_input":"2024-03-15T19:08:52.497590Z","iopub.status.idle":"2024-03-15T19:08:52.503333Z","shell.execute_reply.started":"2024-03-15T19:08:52.497542Z","shell.execute_reply":"2024-03-15T19:08:52.502271Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Training\nmodel_3.compile(optimizer=optimizers.SGD(learning_rate=0.001, momentum=0.9),\n              loss='categorical_crossentropy', \n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:08:52.504911Z","iopub.execute_input":"2024-03-15T19:08:52.505709Z","iopub.status.idle":"2024-03-15T19:08:52.574621Z","shell.execute_reply.started":"2024-03-15T19:08:52.505669Z","shell.execute_reply":"2024-03-15T19:08:52.573726Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(hists)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T17:49:02.386984Z","iopub.execute_input":"2024-03-15T17:49:02.387626Z","iopub.status.idle":"2024-03-15T17:49:02.392094Z","shell.execute_reply.started":"2024-03-15T17:49:02.387598Z","shell.execute_reply":"2024-03-15T17:49:02.391199Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the number of epochs\nepochs = 5\n\n# Train the model\nInceptionResNet = model_3.fit(train_data, \n                    epochs=epochs,\n                    validation_data=val_data,\n                    callbacks = checkpoint)\n\nhists.append(InceptionResNet)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:11:31.773287Z","iopub.execute_input":"2024-03-15T19:11:31.773700Z","iopub.status.idle":"2024-03-15T19:37:44.244064Z","shell.execute_reply.started":"2024-03-15T19:11:31.773668Z","shell.execute_reply":"2024-03-15T19:37:44.242873Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1378/1378 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9521","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"1378/1378 [==============================] - 318s 231ms/step - loss: 0.1411 - accuracy: 0.9521 - val_loss: 0.1120 - val_accuracy: 0.9617\nEpoch 2/5\n1378/1378 [==============================] - 311s 225ms/step - loss: 0.1104 - accuracy: 0.9619 - val_loss: 0.0995 - val_accuracy: 0.9675\nEpoch 3/5\n1378/1378 [==============================] - 311s 225ms/step - loss: 0.1063 - accuracy: 0.9637 - val_loss: 0.0962 - val_accuracy: 0.9679\nEpoch 4/5\n1378/1378 [==============================] - 311s 226ms/step - loss: 0.0940 - accuracy: 0.9679 - val_loss: 0.0893 - val_accuracy: 0.9697\nEpoch 5/5\n1378/1378 [==============================] - 311s 226ms/step - loss: 0.0875 - accuracy: 0.9696 - val_loss: 0.0865 - val_accuracy: 0.9710\n","output_type":"stream"}]},{"cell_type":"code","source":"print (hists)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:40:08.151338Z","iopub.execute_input":"2024-03-15T19:40:08.152158Z","iopub.status.idle":"2024-03-15T19:40:08.157748Z","shell.execute_reply.started":"2024-03-15T19:40:08.152121Z","shell.execute_reply":"2024-03-15T19:40:08.156397Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[<keras.src.callbacks.History object at 0x7f62f9dc0eb0>]\n","output_type":"stream"}]},{"cell_type":"code","source":"for hist in hists:\n    print(hist)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:40:51.955339Z","iopub.execute_input":"2024-03-15T19:40:51.956209Z","iopub.status.idle":"2024-03-15T19:40:51.961974Z","shell.execute_reply.started":"2024-03-15T19:40:51.956167Z","shell.execute_reply":"2024-03-15T19:40:51.960850Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"<keras.src.callbacks.History object at 0x7f62f9dc0eb0>\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming hists is a list containing history objects\ndata = []\nfor history in hists:\n    for epoch in history.epoch:\n        row_data = {'epoch': epoch}\n        for metric_name, metric_values in history.history.items():\n            row_data[metric_name] = metric_values[epoch]\n        data.append(row_data)\n\n# Convert the data to a pandas DataFrame\ndf = pd.DataFrame(data)\n\n# Save the DataFrame to a CSV file\ndf.to_csv('history_data.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:41:10.753414Z","iopub.execute_input":"2024-03-15T19:41:10.754430Z","iopub.status.idle":"2024-03-15T19:41:10.768018Z","shell.execute_reply.started":"2024-03-15T19:41:10.754394Z","shell.execute_reply":"2024-03-15T19:41:10.767114Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.plot(InceptionResNetV2.history['loss'])\nplt.plot(InceptionResNetV2.history['val_loss'])\nplt.title(\"Model loss\")\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['traning_loss', 'validation_loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T19:40:14.620732Z","iopub.execute_input":"2024-03-15T19:40:14.621547Z","iopub.status.idle":"2024-03-15T19:40:14.663423Z","shell.execute_reply.started":"2024-03-15T19:40:14.621515Z","shell.execute_reply":"2024-03-15T19:40:14.662203Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mInceptionResNetV2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(InceptionResNetV2\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'history'"],"ename":"AttributeError","evalue":"'function' object has no attribute 'history'","output_type":"error"}]},{"cell_type":"markdown","source":"# Model 4","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CAM & Accuracy report with random images from val_data","metadata":{}},{"cell_type":"code","source":"def find_last_conv_layer(model):\n    for layer in reversed(model.get_layer('efficientnetv2-l').layers):\n        if isinstance(layer, tf.keras.layers.Conv2D):\n            return layer\n    return None\n\ndef generate_cam(model, image, class_index):\n    last_conv_layer = find_last_conv_layer(model)\n\n    if last_conv_layer is None:\n        raise ValueError(\"No convolutional layers found in the 'efficientnetv2-l' part of the model.\")\n\n\n    submodel = Model(inputs=model.get_layer('efficientnetv2-l').input, outputs=last_conv_layer.output)\n\n    preprocessed_image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n    preprocessed_image = tf.expand_dims(preprocessed_image, axis=0)\n\n    # Computing feature map from the submodel\n    feature_maps = submodel(preprocessed_image)\n\n    class_weights = model.get_layer('output_layer').get_weights()[0]\n\n\n    cam = np.dot(feature_maps.numpy()[0, ..., :], class_weights[:, class_index])\n    cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))\n    cam = cv2.resize(cam, (224, 224))  # Resize to match the image size\n\n    return cam\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.seed(42)\nval_data_iterator = iter(val_data)\nbleeding_class_index = 0\n\n\nbleeding_images = []\n\n\nwhile len(bleeding_images) < 5:\n    \n    batch_images, batch_labels = next(val_data_iterator)\n    \n    \n    for i in range(len(batch_labels)):\n        if batch_labels[i][bleeding_class_index] == 1:\n            bleeding_images.append(batch_images[i])\n            if len(bleeding_images) == 5:\n                break\n\n\nclass_index = 0\n\n\nplt.figure(figsize=(15, 6))\nfor i, image in enumerate(bleeding_images):\n    cam_image = generate_cam(model, image, class_index)\n\n    \n    plt.subplot(2, 5, i + 1)\n    plt.imshow(image / 255.0)  \n    plt.title(f\"Image {i + 1}\")\n\n    \n    plt.subplot(2, 5, i + 6)\n    plt.imshow(image / 255.0)  \n    plt.imshow(cam_image, cmap=\"jet\", alpha=0.5)\n    plt.title(\"CAM\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\n\nval_data_iterator = iter(val_data)\nnum_images_to_plot = 20\nselected_images = []\ntrue_labels = []\n\n\nfor _ in range(num_images_to_plot):\n    \n    batch_images, batch_labels = next(val_data_iterator)\n   \n    random_index = random.randint(0, len(batch_images) - 1)\n    selected_image = batch_images[random_index]\n    selected_label = batch_labels[random_index]\n    \n    selected_images.append(selected_image)\n    true_labels.append(selected_label)\n\nselected_images = np.array(selected_images)\n\npredicted_labels = model.predict(selected_images)\n\npredicted_classes = np.argmax(predicted_labels, axis=1)\n\nclass_names = ['Parasitized', 'Uninfected']\n\n\nplt.figure(figsize=(15, 12))\nfor i in range(num_images_to_plot):\n    plt.subplot(5, 5, i + 1)\n    plt.imshow(selected_images[i] / 255.0) \n    plt.title(f\"Original: {class_names[np.argmax(true_labels[i])]} \\nPredicted: {class_names[predicted_classes[i]]}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_true = []\ny_pred = []\n\nfor images, labels in val_data:\n    predictions = model.predict(images, verbose=0)\n    y_true.extend(tf.argmax(labels, axis=1))\n    y_pred.extend(tf.argmax(predictions, axis=1))\n\nclassification_metrics = classification_report(y_true, y_pred, target_names=[\"bleeding\", \"non-bleeding\"])\nprint(classification_metrics)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_names = []\npredicted_labels = []\n\nfolder_path = \"/kaggle/input/wce-test/Auto-WCEBleedGen Challenge Test Dataset/Test Dataset 2\"\n# Create a function to load and preprocess an image\ndef preprocess_image(file_path):\n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, (224, 224))\n    img = tf.cast(img, tf.float32) / 255.0  \n    return img\n\n# Get a list of image file names in the folder and sort them\nimage_file_names = os.listdir(folder_path)\nimage_file_names.sort()\n\n# Iterate over the images in the folder\nfor image_name in image_file_names:\n    # Remove the file extension (.png) and save only the image name\n    image_name_without_extension = os.path.splitext(image_name)[0]\n    \n    image_path = os.path.join(folder_path, image_name)\n    \n    # Preprocess the image\n    image = preprocess_image(image_path)\n    image = tf.expand_dims(image, axis=0)  \n    predictions = model.predict(image, verbose=0)\n    \n    predicted_class_index = tf.argmax(predictions, axis=1).numpy()[0]\n    predicted_class = \"Bleeding\" if predicted_class_index == 0 else \"Non-Bleeding\"\n    \n    image_names.append(image_name_without_extension)\n    predicted_labels.append(predicted_class)\n\nresult_df = pd.DataFrame({\"Image Name\": image_names, \"Predicted Label\": predicted_labels})\n\nresult_df.to_csv(\"submission2.csv\", index=False)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('bleed.h5')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}